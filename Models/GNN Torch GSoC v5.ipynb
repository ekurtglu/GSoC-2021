{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eca9762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy.matlib\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_curve, auc\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a88d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bb6d782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Dataset, Data, DataLoader\n",
    "import torch_geometric.nn as gnn\n",
    "from torch_geometric.utils import softmax\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a8b6a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "711c1185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Phi_0', 'Phi_2', 'Phi_3', 'Phi_4', 'Theta_0', 'Theta_2',\n",
      "       'Theta_3', 'Theta_4', 'BendingAngle_0', 'BendingAngle_2',\n",
      "       'BendingAngle_3', 'BendingAngle_4', 'TimeInfo_0', 'TimeInfo_2',\n",
      "       'TimeInfo_3', 'TimeInfo_4', 'RingNumber_0', 'RingNumber_2',\n",
      "       'RingNumber_3', 'RingNumber_4', 'Front_0', 'Front_2', 'Front_3',\n",
      "       'Front_4', 'Mask_0', 'Mask_2', 'Mask_3', 'Mask_4',\n",
      "       'PatternStraightness', 'Zone', 'MedianTheta', 'q/pt', 'PhiAngle',\n",
      "       'EtaAngle'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Phi_0</th>\n",
       "      <th>Phi_2</th>\n",
       "      <th>Phi_3</th>\n",
       "      <th>Phi_4</th>\n",
       "      <th>Theta_0</th>\n",
       "      <th>Theta_2</th>\n",
       "      <th>Theta_3</th>\n",
       "      <th>Theta_4</th>\n",
       "      <th>BendingAngle_0</th>\n",
       "      <th>...</th>\n",
       "      <th>Mask_0</th>\n",
       "      <th>Mask_2</th>\n",
       "      <th>Mask_3</th>\n",
       "      <th>Mask_4</th>\n",
       "      <th>PatternStraightness</th>\n",
       "      <th>Zone</th>\n",
       "      <th>MedianTheta</th>\n",
       "      <th>q/pt</th>\n",
       "      <th>PhiAngle</th>\n",
       "      <th>EtaAngle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>58.066666</td>\n",
       "      <td>55.466667</td>\n",
       "      <td>55.466667</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>11.970</td>\n",
       "      <td>11.684999</td>\n",
       "      <td>11.400</td>\n",
       "      <td>11.400</td>\n",
       "      <td>-13.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.181209</td>\n",
       "      <td>-3.075936</td>\n",
       "      <td>1.722345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>64.583336</td>\n",
       "      <td>66.800000</td>\n",
       "      <td>67.066666</td>\n",
       "      <td>67.200000</td>\n",
       "      <td>6.555</td>\n",
       "      <td>6.840000</td>\n",
       "      <td>6.555</td>\n",
       "      <td>6.840</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>-0.146131</td>\n",
       "      <td>-0.167139</td>\n",
       "      <td>2.012122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>71.150000</td>\n",
       "      <td>67.033330</td>\n",
       "      <td>66.266670</td>\n",
       "      <td>65.466670</td>\n",
       "      <td>2.850</td>\n",
       "      <td>2.565000</td>\n",
       "      <td>2.280</td>\n",
       "      <td>2.280</td>\n",
       "      <td>-16.613783</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.367024</td>\n",
       "      <td>2.431823</td>\n",
       "      <td>2.321646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>34.933334</td>\n",
       "      <td>31.200000</td>\n",
       "      <td>31.200000</td>\n",
       "      <td>31.833334</td>\n",
       "      <td>9.690</td>\n",
       "      <td>8.835000</td>\n",
       "      <td>8.835</td>\n",
       "      <td>9.120</td>\n",
       "      <td>-13.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.267774</td>\n",
       "      <td>-1.343305</td>\n",
       "      <td>1.854506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>68.150000</td>\n",
       "      <td>68.266670</td>\n",
       "      <td>68.300000</td>\n",
       "      <td>68.400000</td>\n",
       "      <td>2.565</td>\n",
       "      <td>2.565000</td>\n",
       "      <td>2.565</td>\n",
       "      <td>2.565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>-0.019179</td>\n",
       "      <td>-3.134433</td>\n",
       "      <td>2.333772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179351</th>\n",
       "      <td>1179351</td>\n",
       "      <td>30.450000</td>\n",
       "      <td>29.066668</td>\n",
       "      <td>28.933332</td>\n",
       "      <td>28.933332</td>\n",
       "      <td>9.405</td>\n",
       "      <td>9.120000</td>\n",
       "      <td>9.120</td>\n",
       "      <td>9.120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.118520</td>\n",
       "      <td>0.522333</td>\n",
       "      <td>-1.833125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179352</th>\n",
       "      <td>1179352</td>\n",
       "      <td>39.400000</td>\n",
       "      <td>40.133335</td>\n",
       "      <td>40.266666</td>\n",
       "      <td>40.400000</td>\n",
       "      <td>3.705</td>\n",
       "      <td>3.420000</td>\n",
       "      <td>3.420</td>\n",
       "      <td>3.420</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-0.084559</td>\n",
       "      <td>-1.585937</td>\n",
       "      <td>-2.262504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179353</th>\n",
       "      <td>1179353</td>\n",
       "      <td>65.533330</td>\n",
       "      <td>63.433334</td>\n",
       "      <td>62.933334</td>\n",
       "      <td>63.066666</td>\n",
       "      <td>7.125</td>\n",
       "      <td>6.555000</td>\n",
       "      <td>6.555</td>\n",
       "      <td>6.555</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.173085</td>\n",
       "      <td>1.175915</td>\n",
       "      <td>-1.988468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179354</th>\n",
       "      <td>1179354</td>\n",
       "      <td>41.283333</td>\n",
       "      <td>40.533333</td>\n",
       "      <td>40.366665</td>\n",
       "      <td>40.400000</td>\n",
       "      <td>3.990</td>\n",
       "      <td>3.705000</td>\n",
       "      <td>3.705</td>\n",
       "      <td>3.705</td>\n",
       "      <td>-5.537928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.085662</td>\n",
       "      <td>2.748315</td>\n",
       "      <td>-2.236174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179355</th>\n",
       "      <td>1179355</td>\n",
       "      <td>72.133330</td>\n",
       "      <td>70.533330</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>69.600000</td>\n",
       "      <td>2.850</td>\n",
       "      <td>2.565000</td>\n",
       "      <td>2.565</td>\n",
       "      <td>2.565</td>\n",
       "      <td>-9.229879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.189065</td>\n",
       "      <td>-1.878648</td>\n",
       "      <td>-2.330181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1179356 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0      Phi_0      Phi_2      Phi_3      Phi_4  Theta_0  \\\n",
       "0                 0  58.066666  55.466667  55.466667  56.000000   11.970   \n",
       "1                 1  64.583336  66.800000  67.066666  67.200000    6.555   \n",
       "2                 2  71.150000  67.033330  66.266670  65.466670    2.850   \n",
       "3                 3  34.933334  31.200000  31.200000  31.833334    9.690   \n",
       "4                 4  68.150000  68.266670  68.300000  68.400000    2.565   \n",
       "...             ...        ...        ...        ...        ...      ...   \n",
       "1179351     1179351  30.450000  29.066668  28.933332  28.933332    9.405   \n",
       "1179352     1179352  39.400000  40.133335  40.266666  40.400000    3.705   \n",
       "1179353     1179353  65.533330  63.433334  62.933334  63.066666    7.125   \n",
       "1179354     1179354  41.283333  40.533333  40.366665  40.400000    3.990   \n",
       "1179355     1179355  72.133330  70.533330  70.000000  69.600000    2.850   \n",
       "\n",
       "           Theta_2  Theta_3  Theta_4  BendingAngle_0  ...  Mask_0  Mask_2  \\\n",
       "0        11.684999   11.400   11.400      -13.000000  ...     0.0     0.0   \n",
       "1         6.840000    6.555    6.840        7.000000  ...     0.0     0.0   \n",
       "2         2.565000    2.280    2.280      -16.613783  ...     0.0     0.0   \n",
       "3         8.835000    8.835    9.120      -13.000000  ...     0.0     0.0   \n",
       "4         2.565000    2.565    2.565        0.000000  ...     0.0     0.0   \n",
       "...            ...      ...      ...             ...  ...     ...     ...   \n",
       "1179351   9.120000    9.120    9.120        0.000000  ...     0.0     0.0   \n",
       "1179352   3.420000    3.420    3.420       -0.000000  ...     0.0     0.0   \n",
       "1179353   6.555000    6.555    6.555       -9.000000  ...     0.0     0.0   \n",
       "1179354   3.705000    3.705    3.705       -5.537928  ...     0.0     0.0   \n",
       "1179355   2.565000    2.565    2.565       -9.229879  ...     0.0     0.0   \n",
       "\n",
       "         Mask_3  Mask_4  PatternStraightness  Zone  MedianTheta      q/pt  \\\n",
       "0           0.0     0.0                  5.0   3.0        105.0  0.181209   \n",
       "1           0.0     0.0                  3.0   1.0        124.0 -0.146131   \n",
       "2           0.0     0.0                  7.0   0.0        127.0  0.367024   \n",
       "3           0.0     0.0                  6.0   2.0         60.0  0.267774   \n",
       "4           0.0     0.0                  4.0   0.0        128.0 -0.019179   \n",
       "...         ...     ...                  ...   ...          ...       ...   \n",
       "1179351     0.0     0.0                  5.0   2.0         55.0  0.118520   \n",
       "1179352     0.0     0.0                  4.0   0.0         75.0 -0.084559   \n",
       "1179353     0.0     0.0                  5.0   1.0        120.0  0.173085   \n",
       "1179354     0.0     0.0                  4.0   0.0         77.0  0.085662   \n",
       "1179355     0.0     0.0                  5.0   0.0        133.0  0.189065   \n",
       "\n",
       "         PhiAngle  EtaAngle  \n",
       "0       -3.075936  1.722345  \n",
       "1       -0.167139  2.012122  \n",
       "2        2.431823  2.321646  \n",
       "3       -1.343305  1.854506  \n",
       "4       -3.134433  2.333772  \n",
       "...           ...       ...  \n",
       "1179351  0.522333 -1.833125  \n",
       "1179352 -1.585937 -2.262504  \n",
       "1179353  1.175915 -1.988468  \n",
       "1179354  2.748315 -2.236174  \n",
       "1179355 -1.878648 -2.330181  \n",
       "\n",
       "[1179356 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('input/CMS_trigger.csv')\n",
    "print(df.columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4480e60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_1 = StandardScaler()\n",
    "df.loc[:,'Phi_0':'MedianTheta'] = scaler_1.fit_transform(df.loc[:,'Phi_0':'MedianTheta']) # normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acee0c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Phi_'+str(i) for i in [0,2,3,4]] + ['Theta_'+str(i) for i in [0,2,3,4]] + \\\n",
    "['Front_'+str(i) for i in [0,2,3,4]] + ['BendingAngle_'+str(i) for i in [0,2,3,4]] + \\\n",
    "['TimeInfo_'+str(i) for i in [0,2,3,4]] + ['RingNumber_'+str(i) for i in [0,2,3,4]] + \\\n",
    "['Mask_'+str(i) for i in [0,2,3,4]] #+ ['PatternStraightness'] + ['Zone'] + ['MedianTheta']\n",
    "edge_index = torch.tensor([(0,1),(1,2),(2,3),(3,2),(2,1),(1,0)], dtype=torch.long).T\n",
    "edge_index = [(0,1),(1,2),(2,3),(3,2),(2,1),(1,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d73a1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (1179356, 28)\n",
      "(1179356,)\n",
      "Len train: 943484, Len test: 235872\n",
      "Num. features: 28\n"
     ]
    }
   ],
   "source": [
    "# x_train, x_test, pT_tr, pT_ts, inv_pT_tr, inv_pT_ts = train_test_split(df[features].to_numpy(), abs(1/df.loc[:,'q/pt']).to_numpy(), 1/abs(1/df.loc[:,'q/pt']).to_numpy(), test_size = 0.2, random_state = 1)\n",
    "train_mask, test_mask = train_test_split(df['Unnamed: 0'].to_numpy(), test_size = 0.2, random_state = 1)\n",
    "x_data = df[features].to_numpy()\n",
    "pT = abs(1/df.loc[:,'q/pt']).to_numpy()\n",
    "inv_pT = 1/pT\n",
    "if inv:\n",
    "    label = inv_pT\n",
    "    lr = 0.002\n",
    "else:\n",
    "    label = pT\n",
    "    lr = 0.01\n",
    "num_features = x_data.shape[-1]\n",
    "print('Data shape: ' + str(x_data.shape))\n",
    "print(pT.shape)\n",
    "print('Len train: '+str(len(train_mask))+', Len test: '+str(len(test_mask)))\n",
    "print('Num. features: '+str(num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "060e0769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(i):\n",
    "    \n",
    "    data = Data(x=torch.tensor(x_data[i].reshape(-1,4).T, dtype=torch.float), y=torch.tensor(label[i], dtype=torch.float),\n",
    "                edge_index=torch.tensor(edge_index, dtype = torch.long).T)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d852c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPL(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MPL, self).__init__(aggr='add')\n",
    "        self.mlp1 = torch.nn.Linear(in_channels*2, out_channels)\n",
    "        self.mlp2 = torch.nn.Linear(in_channels, out_channels)\n",
    "        self.mlp3 = torch.nn.Linear(2*out_channels, 1)\n",
    "        self.mlp4 = torch.nn.Linear(2*out_channels, 1)\n",
    "        self.mlp5 = torch.nn.Linear(in_channels,16)\n",
    "        self.mlp6 = torch.nn.Linear(out_channels,16)\n",
    "        self.mlp7 = torch.nn.Linear(16,1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "#         edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        msg = self.propagate(edge_index, x=x)\n",
    "        x = F.relu(self.mlp2(x))\n",
    "        w1 = F.sigmoid(self.mlp3(torch.cat([x,msg], dim=1)))\n",
    "        w2 = F.sigmoid(self.mlp4(torch.cat([x,msg], dim=1)))\n",
    "        out = w1*msg + w2*x\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def message(self, x_i, x_j, edge_index):\n",
    "        msg = F.relu(self.mlp1(torch.cat([x_i, x_j-x_i], dim=1)))\n",
    "        w1 = F.tanh(self.mlp5(x_i))\n",
    "        w2 = F.tanh(self.mlp6(msg))\n",
    "        w = self.mlp7(w1*w2)\n",
    "        w = softmax(w, edge_index[0])\n",
    "        return msg*w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "748dc2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MPNN, self).__init__()\n",
    "        self.conv1 = MPL(7,128 )\n",
    "        self.conv2 = MPL(128,64)\n",
    "        self.conv3 = MPL(64,64 )\n",
    "        self.conv4 = MPL(64,64 )\n",
    "        self.lin1 = torch.nn.Linear(128, 128)\n",
    "        self.lin2 = torch.nn.Linear(128, 16)\n",
    "        self.lin3 = torch.nn.Linear(16, 16)\n",
    "        self.lin4 = torch.nn.Linear(16, 1)\n",
    "        self.lin5 = torch.nn.Linear(128, 128)\n",
    "        self.lin6 = torch.nn.Linear(128, 16)\n",
    "        self.lin7 = torch.nn.Linear(16, 16)\n",
    "        self.lin8 = torch.nn.Linear(16, 1)\n",
    "        self.global_att_pool1 = gnn.GlobalAttention(torch.nn.Sequential(torch.nn.Linear(64, 1)))\n",
    "        self.global_att_pool2 = gnn.GlobalAttention(torch.nn.Sequential(torch.nn.Linear(64, 1)))\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x1 = self.global_att_pool1(x, batch)\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = F.relu(self.conv4(x, edge_index))\n",
    "        x2 = self.global_att_pool2(x, batch)\n",
    "        x_out = torch.cat([x1, x2], dim=1)\n",
    "        x = F.relu(self.lin1(x_out))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = self.lin3(x)\n",
    "        x = self.lin4(x).squeeze(1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f91d9fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, indices=list(range(len(df))), transform=None):\n",
    "        self.transform = transform\n",
    "        self.indices = indices\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return process_data(self.indices[idx])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8444907d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(prog_bar = True):\n",
    "    \n",
    "    train_losses, test_losses = list(), list()\n",
    "    min_test_loss = float('inf')\n",
    "    train_loader = DataLoader(MyDataset(indices=train_mask), batch_size=batch_size)\n",
    "    test_loader = DataLoader(MyDataset(indices=test_mask), batch_size=batch_size)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "        test_loss = 0\n",
    "        if prog_bar:\n",
    "            pbar = tqdm(train_loader,position=0)\n",
    "        else:\n",
    "            pbar = train_loader\n",
    "            \n",
    "        # train\n",
    "        for data in pbar:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            labels = data.y\n",
    "            loss = F.mse_loss(out, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if prog_bar:\n",
    "                pbar.set_description('MSELoss: '+str(loss.cpu().detach().numpy()))\n",
    "                train_loss += loss.cpu().detach()/len(train_loader)\n",
    "                \n",
    "        # test\n",
    "        for data in test_loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            labels = data.y\n",
    "            loss = F.mse_loss(out, data.y)\n",
    "            test_loss += loss.cpu().detach()/len(test_loader)\n",
    "            if test_loss.detach().numpy()<min_test_loss:\n",
    "                min_test_loss = test_loss.cpu().detach().numpy()\n",
    "                torch.save(model.state_dict(), model_name)\n",
    "        \n",
    "        lr_scheduler.step(test_loss)\n",
    "        print('Epoch: ', str(epoch+1)+'/'+str(epochs),'| Training MSELoss: ', train_loss.numpy(), '| Testing MSELoss: ', test_loss.numpy())\n",
    "        train_losses.append(train_loss.numpy())\n",
    "        test_losses.append(test_loss.numpy())\n",
    "\n",
    "        \n",
    "        if not prog_bar:\n",
    "            plt.plot(train_losses, label=\"Train Loss\")\n",
    "            plt.plot(test_losses, label=\"Validation Loss\")\n",
    "            plt.xlabel(\"# Epoch\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.legend(loc='upper right')\n",
    "            plt.show()\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4392942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var nb = IPython.notebook;\n",
       "var kernel = IPython.notebook.kernel;\n",
       "var command = \"NOTEBOOK_FULL_PATH = '\" + nb.base_url + nb.notebook_path + \"'\";\n",
       "kernel.execute(command);\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "var nb = IPython.notebook;\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var command = \"NOTEBOOK_FULL_PATH = '\" + nb.base_url + nb.notebook_path + \"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a77f1ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 15191.454: 100%|████████████████████████████████████████████████████████████| 103/103 [01:11<00:00,  1.43it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1/30 | Training MSELoss:  18029.66 | Testing MSELoss:  19352.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 14784.554: 100%|████████████████████████████████████████████████████████████| 103/103 [01:10<00:00,  1.46it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2/30 | Training MSELoss:  17686.207 | Testing MSELoss:  18999.422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 14378.135: 100%|████████████████████████████████████████████████████████████| 103/103 [01:10<00:00,  1.46it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3/30 | Training MSELoss:  17183.074 | Testing MSELoss:  18464.342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 13118.091: 100%|████████████████████████████████████████████████████████████| 103/103 [01:11<00:00,  1.45it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4/30 | Training MSELoss:  17007.309 | Testing MSELoss:  17791.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 14589.351: 100%|████████████████████████████████████████████████████████████| 103/103 [01:11<00:00,  1.44it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5/30 | Training MSELoss:  17194.455 | Testing MSELoss:  18856.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 14713.41: 100%|█████████████████████████████████████████████████████████████| 103/103 [01:10<00:00,  1.46it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     6: reducing learning rate of group 0 to 5.0000e-03.\n",
      "Epoch:  6/30 | Training MSELoss:  17513.762 | Testing MSELoss:  18884.084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 14624.74: 100%|█████████████████████████████████████████████████████████████| 103/103 [01:09<00:00,  1.47it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7/30 | Training MSELoss:  17463.564 | Testing MSELoss:  18882.143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 14169.937: 100%|████████████████████████████████████████████████████████████| 103/103 [01:09<00:00,  1.47it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch     8: reducing learning rate of group 0 to 2.5000e-03.\n",
      "Epoch:  8/30 | Training MSELoss:  17357.39 | Testing MSELoss:  18507.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 14538.262: 100%|████████████████████████████████████████████████████████████| 103/103 [01:08<00:00,  1.50it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9/30 | Training MSELoss:  17107.836 | Testing MSELoss:  18511.734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 14413.933: 100%|████████████████████████████████████████████████████████████| 103/103 [01:08<00:00,  1.49it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    10: reducing learning rate of group 0 to 1.2500e-03.\n",
      "Epoch:  10/30 | Training MSELoss:  17216.926 | Testing MSELoss:  18757.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 14220.653: 100%|████████████████████████████████████████████████████████████| 103/103 [01:09<00:00,  1.49it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  11/30 | Training MSELoss:  17203.012 | Testing MSELoss:  18432.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 13986.049: 100%|████████████████████████████████████████████████████████████| 103/103 [01:09<00:00,  1.49it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    12: reducing learning rate of group 0 to 6.2500e-04.\n",
      "Epoch:  12/30 | Training MSELoss:  17052.398 | Testing MSELoss:  18346.543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 13923.948: 100%|████████████████████████████████████████████████████████████| 103/103 [01:08<00:00,  1.51it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  13/30 | Training MSELoss:  16918.352 | Testing MSELoss:  18247.469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 13954.468: 100%|████████████████████████████████████████████████████████████| 103/103 [01:08<00:00,  1.51it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    14: reducing learning rate of group 0 to 3.1250e-04.\n",
      "Epoch:  14/30 | Training MSELoss:  16865.953 | Testing MSELoss:  18202.818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 13671.584: 100%|████████████████████████████████████████████████████████████| 103/103 [01:08<00:00,  1.50it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  15/30 | Training MSELoss:  16781.836 | Testing MSELoss:  18143.264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 13675.032: 100%|████████████████████████████████████████████████████████████| 103/103 [01:07<00:00,  1.52it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    16: reducing learning rate of group 0 to 1.5625e-04.\n",
      "Epoch:  16/30 | Training MSELoss:  16743.072 | Testing MSELoss:  18113.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 13729.102: 100%|████████████████████████████████████████████████████████████| 103/103 [01:08<00:00,  1.51it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  17/30 | Training MSELoss:  16738.906 | Testing MSELoss:  18133.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 13690.478: 100%|████████████████████████████████████████████████████████████| 103/103 [01:08<00:00,  1.51it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    18: reducing learning rate of group 0 to 7.8125e-05.\n",
      "Epoch:  18/30 | Training MSELoss:  16712.252 | Testing MSELoss:  18095.748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 13601.647: 100%|████████████████████████████████████████████████████████████| 103/103 [01:08<00:00,  1.51it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  19/30 | Training MSELoss:  16680.344 | Testing MSELoss:  18088.453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 13587.753: 100%|████████████████████████████████████████████████████████████| 103/103 [01:07<00:00,  1.52it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    20: reducing learning rate of group 0 to 3.9063e-05.\n",
      "Epoch:  20/30 | Training MSELoss:  16666.729 | Testing MSELoss:  18078.281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 13624.384: 100%|████████████████████████████████████████████████████████████| 103/103 [01:07<00:00,  1.52it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  21/30 | Training MSELoss:  16662.13 | Testing MSELoss:  18075.242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 13623.808: 100%|████████████████████████████████████████████████████████████| 103/103 [01:07<00:00,  1.52it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    22: reducing learning rate of group 0 to 1.9531e-05.\n",
      "Epoch:  22/30 | Training MSELoss:  16656.195 | Testing MSELoss:  18076.492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 13618.645: 100%|████████████████████████████████████████████████████████████| 103/103 [01:07<00:00,  1.52it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  23/30 | Training MSELoss:  16651.89 | Testing MSELoss:  18072.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 13617.917: 100%|████████████████████████████████████████████████████████████| 103/103 [01:07<00:00,  1.52it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    24: reducing learning rate of group 0 to 9.7656e-06.\n",
      "Epoch:  24/30 | Training MSELoss:  16649.148 | Testing MSELoss:  18070.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 13607.476: 100%|████████████████████████████████████████████████████████████| 103/103 [01:07<00:00,  1.52it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  25/30 | Training MSELoss:  16645.63 | Testing MSELoss:  18070.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 13606.5625: 100%|███████████████████████████████████████████████████████████| 103/103 [01:08<00:00,  1.51it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    26: reducing learning rate of group 0 to 4.8828e-06.\n",
      "Epoch:  26/30 | Training MSELoss:  16645.287 | Testing MSELoss:  18069.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 13606.091: 100%|████████████████████████████████████████████████████████████| 103/103 [01:07<00:00,  1.52it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  27/30 | Training MSELoss:  16643.916 | Testing MSELoss:  18069.486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 13604.99: 100%|█████████████████████████████████████████████████████████████| 103/103 [01:08<00:00,  1.50it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    28: reducing learning rate of group 0 to 2.4414e-06.\n",
      "Epoch:  28/30 | Training MSELoss:  16643.303 | Testing MSELoss:  18068.836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 13604.101: 100%|████████████████████████████████████████████████████████████| 103/103 [01:11<00:00,  1.43it/s]\n",
      "  0%|                                                                                          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  29/30 | Training MSELoss:  16642.867 | Testing MSELoss:  18068.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MSELoss: 13604.114: 100%|████████████████████████████████████████████████████████████| 103/103 [01:12<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    30: reducing learning rate of group 0 to 1.2207e-06.\n",
      "Epoch:  30/30 | Training MSELoss:  16642.682 | Testing MSELoss:  18068.357\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "batch_size = 9192\n",
    "epochs = 30\n",
    "model = MPNN().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.002, weight_decay=5e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=1, factor=0.5)\n",
    "\n",
    "model_name = 'C:/Users/emrek/' + NOTEBOOK_FULL_PATH[:-6] + 'inv_' + str(inv) + '.pth'\n",
    "train_losses, test_losses = train(prog_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e717786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'C:/Users/emrek/' + NOTEBOOK_FULL_PATH[:-6] + 'inv_' + str(inv) + '.pth'\n",
    "batch_size = 512\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "loaded_model = MPNN().to(device)\n",
    "optimizer = torch.optim.Adam(loaded_model.parameters(), lr=0.002, weight_decay=5e-4)\n",
    "loaded_model.load_state_dict(torch.load(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f35651c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 461/461 [00:21<00:00, 21.23it/s]\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(MyDataset(indices=test_mask), batch_size=batch_size)\n",
    "# test\n",
    "test_los = 0\n",
    "preds = []\n",
    "for data in tqdm(test_loader,position=0):\n",
    "    data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    out = loaded_model(data)\n",
    "    preds.append(out.cpu().detach())\n",
    "    labels = data.y\n",
    "    loss = F.mse_loss(out, data.y)\n",
    "    test_los += loss.cpu().detach()/len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05a90eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ls = [float(i) for p in preds for i in p]\n",
    "len(pred_ls)\n",
    "df_pred = pd.DataFrame(pred_ls)\n",
    "df_pred.to_csv('C:/Users/emrek/' + NOTEBOOK_FULL_PATH[:-6] + ' inv_' + str(inv)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f537dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02629c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac928e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
